{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing the Machine Learning Pipeline Functions\n",
    "\n",
    "This script provides basic testing of the functionality of the machine learning preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pylidc as pl\n",
    "import cv2\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single nodule stack is queried for the purpose of this script. It is stored as 2D and as 3D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dicom files ... This may take a moment.\n",
      "Loading dicom files ... This may take a moment.\n"
     ]
    }
   ],
   "source": [
    "malignancy_estimate = 5\n",
    "\n",
    "ann = pl.query(pl.Annotation).filter(pl.Annotation.malignancy == malignancy_estimate)\n",
    "\n",
    "padding = [(30,10), (10,25), (0,0)]\n",
    "\n",
    "nodule_slices_2d = []\n",
    "for nodule_slice in ann[:1]:\n",
    "    vol = nodule_slice.scan.to_volume()\n",
    "    bbox = nodule_slice.bbox(pad=padding)\n",
    "    y = vol[bbox]\n",
    "    for i in range(vol[bbox].shape[2]):\n",
    "        nodule_slices_2d.append(vol[bbox][:,:,i])\n",
    "        \n",
    "np_nodules_2d = np.array(nodule_slices_2d)\n",
    "        \n",
    "nodules_3d = []\n",
    "\n",
    "for nodule in ann[:1]:\n",
    "    nodule_container = []\n",
    "    vol = nodule.scan.to_volume()\n",
    "    bbox = nodule.bbox(pad=padding)\n",
    "    y = vol[bbox]\n",
    "    for i in range(vol[bbox].shape[2]):\n",
    "        nodule_container.append(vol[bbox][:,:,i])\n",
    "    nodules_3d.append(nodule_container)\n",
    "    \n",
    "np_nodules_3d = []\n",
    "for nodule in nodules_3d:\n",
    "    np_nodules_3d.append(np.array(nodule))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test 1\n",
    "\n",
    "The 2D resizing and labelling function is tested here. Regardless of the initial size of the slice, the returned image must be of size 227x227. Furthermore, it must be labelled with an integer, either 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress2d(slices, cancer=True):\n",
    "    newSlices = []  \n",
    "    if cancer == True:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "    for slice in slices:\n",
    "        y = cv2.resize(np.array(slice),(227,227))      \n",
    "        newSlices.append([y, label])\n",
    "    return newSlices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size: (88, 74)\n",
      "New Size:  (227, 227)\n",
      "Label:  1\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Size:\" ,np_nodules_2d[0].shape)\n",
    "resized_nodules_2d = compress2d(np_nodules_2d)\n",
    "print(\"New Size: \", resized_nodules_2d[0][0].shape)\n",
    "print(\"Label: \", resized_nodules_2d[0][1])\n",
    "\n",
    "if resized_nodules_2d[0][0].shape == (227,227) and resized_nodules_2d[0][1] == (0 or 1):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test 2\n",
    "\n",
    "The 3D resizing and labelling function is tested here. Regardless of the initial size of the slice, the returned list must contain 20 images of size 111x111. Furthermore, the data must be labelled with an integer, either 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress3d(slices, cancer=True):\n",
    "    newSlices = []  \n",
    "    for slice in slices:\n",
    "        y = cv2.resize(np.array(slice),(111,111))\n",
    "        newSlices.append(y)        \n",
    "    l = len(slices)\n",
    "    x = l/20\n",
    "    if cancer == True:\n",
    "        label = 1\n",
    "        return [zoom(newSlices, (1/x, 1, 1)), label]\n",
    "    else:\n",
    "        label = 0\n",
    "        return [zoom(newSlices, (1/x, 1, 1)), label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: (8, 88, 74)\n",
      "New size:  (20, 111, 111)\n",
      "Label:  1\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "print(\"Original size:\", np_nodules_3d[0].shape)\n",
    "resized_nodules_3d = compress3d(np_nodules_3d[0])\n",
    "print(\"New size: \", resized_nodules_3d[0].shape)\n",
    "print(\"Label: \", resized_nodules_3d[1])\n",
    "\n",
    "if resized_nodules_3d[0].shape == (20,111,111) and resized_nodules_3d[1] == (0 or 1):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test 3\n",
    "\n",
    "The normalization function is tested here. It is expected to return an image whose pixels fall within the range [0,1]. Although normalizing with a min_max technique should change the minimum pixel to 0.0 and the maximum to 1.0, in this case the minimum and maximum bounds were slightly altered to account for outliers, and thus the resulting minimum/maximum values are not necessarily 0.0/1.0, although they always fall within this range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_BOUND = -1100\n",
    "MAX_BOUND = 600\n",
    "\n",
    "def min_max_normalize(image):\n",
    "    image2 = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    image2[image2>1] = 1.\n",
    "    image2[image2<0] = 0.\n",
    "    return image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original minimum pixel:  -899 Original maximum pixel:  431\n",
      "New minimum pixel:  0.11823529411764706 New maximum pixel:  0.9005882352941177\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "print(\"Original minimum pixel: \", resized_nodules_2d[0][0].min(), \"Original maximum pixel: \", resized_nodules_2d[0][0].max())\n",
    "normalized_image = min_max_normalize(resized_nodules_2d[0][0])\n",
    "print(\"New minimum pixel: \", normalized_image.min(), \"New maximum pixel: \", normalized_image.max())\n",
    "\n",
    "if 0 <= normalized_image.min() <= 1:\n",
    "    if 0 <= normalized_image.max() <= 1:        \n",
    "        print(\"Success\")\n",
    "    else:\n",
    "        print(\"Fail\")\n",
    "        \n",
    "print(test_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test 4\n",
    "\n",
    "The stacking function is tested here. It is expected to stack an image on itself thrice, expanding across one dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_data(concatenated_data):\n",
    "\n",
    "    shuffled_stack = []\n",
    "    for nod in concatenated_data: \n",
    "        nod_tuple = []\n",
    "        label = nod[1]\n",
    "        stacked_img = np.stack((nod[0],)*3, axis=-1)\n",
    "        nod_tuple.append(stacked_img)\n",
    "        nod_tuple.append(label)\n",
    "        shuffled_stack.append(nod_tuple)\n",
    "        \n",
    "    return shuffled_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (227, 227)\n",
      "New shape: (227, 227, 3)\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "print(\"Original shape:\", resized_nodules_2d[0][0].shape)\n",
    "stacked_data = stack_data(resized_nodules_2d)\n",
    "print(\"New shape:\", stacked_data[0][0].shape)\n",
    "\n",
    "if stacked_data[0][0].shape == (227,227,3):\n",
    "    print(\"Success\")\n",
    "else:\n",
    "    print(\"Fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test 5\n",
    "\n",
    "This function is expected to split a dataset according to a given ratio, returning the two partitions of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, ratio_of_train):\n",
    "    training_data = []\n",
    "    testing_data = []\n",
    "    num_of_samples = len(data)\n",
    "    len_of_training_data = int(ratio_of_train*num_of_samples)\n",
    "    len_of_testing_data = num_of_samples - len_of_training_data\n",
    "    \n",
    "    for i in range(len_of_training_data):\n",
    "        training_data.append(data[i])\n",
    "    for i in range(len_of_training_data, num_of_samples):\n",
    "        testing_data.append(data[i])\n",
    "        \n",
    "    return training_data, testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_1 = []\n",
    "case_2 = [1 for i in range(33)]\n",
    "case_3 = [1 for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = split_data(case_1, 0.8)\n",
    "results_2 = split_data(case_1, 0)\n",
    "results_3 = split_data(case_2, 0.5)\n",
    "results_4 = split_data(case_2, 0.99)\n",
    "results_5 = split_data(case_3, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "test_status = \"Success\"\n",
    "\n",
    "if results_1 != ([],[]):\n",
    "    test_status = \"Fail\"\n",
    "    \n",
    "if results_2 != ([],[]):\n",
    "    test_status = \"Fail\"\n",
    "    \n",
    "if results_3 != ([1 for i in range(16)],[1 for i in range(17)]):\n",
    "    test_status = \"Fail\"\n",
    "    \n",
    "if results_4 != ([1 for i in range(32)],[1 for i in range(1)]):\n",
    "    test_status = \"Fail\"\n",
    "        \n",
    "if results_5 != ([1 for i in range(80)],[1 for i in range(20)]):\n",
    "    test_status = \"Fail\"\n",
    "    \n",
    "print(test_status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
